{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Sketcher.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatemehTahavori/QuickDraw/blob/main/Copy_of_Sketcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H3ATAdp_URp"
      },
      "source": [
        "# Get the Class names "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlx6-LFL_jbi"
      },
      "source": [
        "This file contains a subset of the quick draw classes. I choose around 100 classes from the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXv-xzU1sd88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6c7cc8-93e5-4b7e-e67e-08c480a06546"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-10 20:52:48--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘mini_classes.txt.1’\n",
            "\n",
            "\rmini_classes.txt.1    0%[                    ]       0  --.-KB/s               \rmini_classes.txt.1  100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-10 20:52:48 (45.3 MB/s) - ‘mini_classes.txt.1’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL_TdMffD6-"
      },
      "source": [
        "Read the classes names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-OxOx5sy0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583acd13-dd73-4ee2-b8e7-e7b26458d0f3"
      },
      "source": [
        "f = open(\"mini_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "print(classes)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['drums\\n', 'sun\\n', 'laptop\\n', 'anvil\\n', 'baseball_bat\\n', 'ladder\\n', 'eyeglasses\\n', 'grapes\\n', 'book\\n', 'dumbbell\\n', 'traffic_light\\n', 'wristwatch\\n', 'wheel\\n', 'shovel\\n', 'bread\\n', 'table\\n', 'tennis_racquet\\n', 'cloud\\n', 'chair\\n', 'headphones\\n', 'face\\n', 'eye\\n', 'airplane\\n', 'snake\\n', 'lollipop\\n', 'power_outlet\\n', 'pants\\n', 'mushroom\\n', 'star\\n', 'sword\\n', 'clock\\n', 'hot_dog\\n', 'syringe\\n', 'stop_sign\\n', 'mountain\\n', 'smiley_face\\n', 'apple\\n', 'bed\\n', 'shorts\\n', 'broom\\n', 'diving_board\\n', 'flower\\n', 'spider\\n', 'cell_phone\\n', 'car\\n', 'camera\\n', 'tree\\n', 'square\\n', 'moon\\n', 'radio\\n', 'hat\\n', 'pizza\\n', 'axe\\n', 'door\\n', 'tent\\n', 'umbrella\\n', 'line\\n', 'cup\\n', 'fan\\n', 'triangle\\n', 'basketball\\n', 'pillow\\n', 'scissors\\n', 't-shirt\\n', 'tooth\\n', 'alarm_clock\\n', 'paper_clip\\n', 'spoon\\n', 'microphone\\n', 'candle\\n', 'pencil\\n', 'envelope\\n', 'saw\\n', 'frying_pan\\n', 'screwdriver\\n', 'helmet\\n', 'bridge\\n', 'light_bulb\\n', 'ceiling_fan\\n', 'key\\n', 'donut\\n', 'bird\\n', 'circle\\n', 'beard\\n', 'coffee_cup\\n', 'butterfly\\n', 'bench\\n', 'rifle\\n', 'cat\\n', 'sock\\n', 'ice_cream\\n', 'moustache\\n', 'suitcase\\n', 'hammer\\n', 'rainbow\\n', 'knife\\n', 'cookie\\n', 'baseball\\n', 'lightning\\n', 'bicycle\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE6D3uxtMc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909afeb7-69e8-4a1f-aa67-36a59a5171fe"
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
        "print(classes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['drums', 'sun', 'laptop', 'anvil', 'baseball_bat', 'ladder', 'eyeglasses', 'grapes', 'book', 'dumbbell', 'traffic_light', 'wristwatch', 'wheel', 'shovel', 'bread', 'table', 'tennis_racquet', 'cloud', 'chair', 'headphones', 'face', 'eye', 'airplane', 'snake', 'lollipop', 'power_outlet', 'pants', 'mushroom', 'star', 'sword', 'clock', 'hot_dog', 'syringe', 'stop_sign', 'mountain', 'smiley_face', 'apple', 'bed', 'shorts', 'broom', 'diving_board', 'flower', 'spider', 'cell_phone', 'car', 'camera', 'tree', 'square', 'moon', 'radio', 'hat', 'pizza', 'axe', 'door', 'tent', 'umbrella', 'line', 'cup', 'fan', 'triangle', 'basketball', 'pillow', 'scissors', 't-shirt', 'tooth', 'alarm_clock', 'paper_clip', 'spoon', 'microphone', 'candle', 'pencil', 'envelope', 'saw', 'frying_pan', 'screwdriver', 'helmet', 'bridge', 'light_bulb', 'ceiling_fan', 'key', 'donut', 'bird', 'circle', 'beard', 'coffee_cup', 'butterfly', 'bench', 'rifle', 'cat', 'sock', 'ice_cream', 'moustache', 'suitcase', 'hammer', 'rainbow', 'knife', 'cookie', 'baseball', 'lightning', 'bicycle']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDfBHVjACAt"
      },
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MC_PUS-fKjH"
      },
      "source": [
        "Loop over the classes and download the currospondent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSUnpL0u22Q"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DPhL5FtWcQ"
      },
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jF6TXXu-Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e953d92-e060-464b-f183-47af32a64cc5"
      },
      "source": [
        "download() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdnbBVXAI-X"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FYrPgOKh6t"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "#from tensorflow.keras import layers\n",
        "#from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30ipBPAQ5Y"
      },
      "source": [
        "# Load the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBq3GXEKAYuO"
      },
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEIgQNHYQnl"
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUjN-WL2Y9"
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGEDS0SMgLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf1e71b-8308-46d6-eec9-89fe5d9ca12d"
      },
      "source": [
        "print(len(x_train))\n",
        "print(np.shape(x_train))\n",
        "x_train.resize(len(x_train), 1, 28, 28)\n",
        "print(np.shape(x_train))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320000\n",
            "(320000, 784)\n",
            "(320000, 1, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWepvc6CsMtL",
        "outputId": "a2f4d394-b10e-4808-b9ad-378789c0ca63"
      },
      "source": [
        "print(len(y_train))\n",
        "print(np.shape(y_train))\n",
        "print(len(x_test))\n",
        "print(np.shape(x_test))\n",
        "x_test.resize(len(x_test), 1, 28, 28)\n",
        "print(np.shape(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320000\n",
            "(320000,)\n",
            "80000\n",
            "(80000, 784)\n",
            "(80000, 1, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZmQvBWBBHE"
      },
      "source": [
        "Show some random data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpDaHRkyMQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fecade04-733b-4744-f3bc-5acc6fe761ba"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chair\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8InHz5NBFrV"
      },
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHUq7D2r9e"
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HID7lwpIxAZ_",
        "outputId": "de5bece1-795b-4c25-90e6-e81d5788a728"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chair\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL6XAb4hBMSc"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUVV2wf2z8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "2ea0c669-7b53-4151-bae0-f1f2437d24ec"
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.train.AdamOptimizer()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-80fed0d4900d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m model.add(layers.Convolution2D(16, (3, 3),\n\u001b[1;32m      4\u001b[0m                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         input_shape=x_train.shape[1:], activation='relu'))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nputN-TossfH",
        "outputId": "6c67ca89-7416-473e-8416-be3065dbc0cb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "        self.fc1 = nn.Linear(32*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        print(x.shape)\n",
        "        x = x.view(-1, 32 * 4 * 4)\n",
        "        print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        print(x.shape)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        print(x.shape)\n",
        "        x = self.fc3(x)\n",
        "        print(x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n",
        "x = torch.rand(2, 1, 28,28)\n",
        "y = net(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 16, 12, 12])\n",
            "torch.Size([2, 32, 4, 4])\n",
            "torch.Size([2, 512])\n",
            "torch.Size([2, 120])\n",
            "torch.Size([2, 84])\n",
            "torch.Size([2, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04lWtAeZPVD7",
        "outputId": "8454aacc-a72d-4692-bef0-fd3e2582e12b"
      },
      "source": [
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=800, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EJUJ64zA4L8"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9s4SEozQ_vM"
      },
      "source": [
        "class SimpleLoader(object):\n",
        "  def __init__(self, data, labels, batch_size=32):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size \n",
        "    self.prepare()\n",
        "\n",
        "  def prepare(self):\n",
        "    self.niters = self.data.shape[0]//self.batch_size\n",
        "  \n",
        "  def get_random_batch(self):\n",
        "    bid = np.random.choice(self.niters)\n",
        "    return self.data[bid*self.batch_size:(bid+1)*self.batch_size], self.labels[bid*self.batch_size:(bid+1)*self.batch_size]  # TODO: turn to tensor\n",
        "\n",
        "mytrainloader = SimpleLoader(x_train, y_train)\n",
        "mytestloader = SimpleLoader(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZA1lgfuTzcv"
      },
      "source": [
        "for i in range(10000):\n",
        "  x,y = mytrainloader.get_random_batch()\n",
        "  optimizer.zero_grad()\n",
        "  pred = net(x)\n",
        "  loss = criterion(pred, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRSRkOyBP1P"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMEJ7kF3lsP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4d9a46ad-2ed1-4b4f-c1ec-687997025034"
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 288000 samples, validate on 32000 samples\n",
            "Epoch 1/5\n",
            " - 14s - loss: 1.8775 - top_k_categorical_accuracy: 0.7930 - val_loss: 1.3543 - val_top_k_categorical_accuracy: 0.8811\n",
            "Epoch 2/5\n",
            " - 13s - loss: 1.2097 - top_k_categorical_accuracy: 0.8960 - val_loss: 1.1262 - val_top_k_categorical_accuracy: 0.9063\n",
            "Epoch 3/5\n",
            " - 13s - loss: 1.0523 - top_k_categorical_accuracy: 0.9132 - val_loss: 1.0283 - val_top_k_categorical_accuracy: 0.9166\n",
            "Epoch 4/5\n",
            " - 13s - loss: 0.9646 - top_k_categorical_accuracy: 0.9220 - val_loss: 0.9908 - val_top_k_categorical_accuracy: 0.9186\n",
            "Epoch 5/5\n",
            " - 13s - loss: 0.9038 - top_k_categorical_accuracy: 0.9282 - val_loss: 0.9460 - val_top_k_categorical_accuracy: 0.9235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1a2f22be10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "DZ79mlEjBDVa",
        "outputId": "7dcc0ec2-6025-4611-d93e-4cb9737d76a2"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    # for i, data in enumerate(trainloader, 0):\n",
        "    for i in range(len(x_train)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        # inputs, labels = data\n",
        "        inputs = x_train[i].reshape(28,28)\n",
        "        inputs = torch.from_numpy(inputs)\n",
        "        labels = (y_train[i])\n",
        "        #print(labels)\n",
        "        #labels = torch.from_numpy(labels)\n",
        "        labels = torch.tensor(labels).float().unsqueeze(0)\n",
        "\n",
        "\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-87d6009648f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-2f206af40c55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 5, 5], but got 2-dimensional input of size [28, 28] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KztY7qEn9_"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssaZczS7DxeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63f7726d-205e-4cf7-9540-0c3d379e54e4"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 92.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBM_w0VBbNr"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3JfoiYHdpk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ca2ed216-7069-4caf-b72a-784a11da8553"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alarm_clock', 'bread', 't-shirt', 'butterfly', 'bird']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndBEPqNBFPKBCF/HA/wNSuG+7tunptgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe3c10abc88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPp5D82YBhM-"
      },
      "source": [
        "# Store the classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFI1msFYpCN"
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJ6dpaDBpRx"
      },
      "source": [
        "# Install TensorFlowJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJDfp9mY9Xh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "5f1b0500-99ca-4935-89da-d2359bb5c29b"
      },
      "source": [
        "!pip install tensorflowjs "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/fd/39f5e1709a543cdce74f2ff6423d70800dbb785494ff66765464feeb67a5/tensorflowjs-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow==1.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Collecting keras==2.1.4 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/45/a273fe3f8fe931a11da34fba1cb74013cfc70dcf93e5d8d329c951dc44c5/Keras-2.1.4-py2.py3-none-any.whl (322kB)\n",
            "\u001b[K    100% |████████████████████████████████| 327kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.7.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.7.1)\n",
            "Collecting numpy==1.14.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/7d/348c5d8d44443656e76285aa97b828b6dbd9c10e5b9c0f7f98eff0ff70e4/numpy-1.14.1-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.2MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub==0.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.6.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (3.5.2.post1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.31.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.4->tensorflowjs) (0.19.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.4->tensorflowjs) (3.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8.0->tensorflowjs) (39.2.0)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (1.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (2.6.11)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (0.14.1)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (0.9999999)\n",
            "Installing collected packages: numpy, keras, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.3\n",
            "    Uninstalling numpy-1.14.3:\n",
            "      Successfully uninstalled numpy-1.14.3\n",
            "  Found existing installation: Keras 2.1.6\n",
            "    Uninstalling Keras-2.1.6:\n",
            "      Successfully uninstalled Keras-2.1.6\n",
            "Successfully installed keras-2.1.4 numpy-1.14.1 tensorflowjs-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBl0ZKVB00d"
      },
      "source": [
        "# Save and Convert "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVICB3TbZGb2"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWWlGdWZOvs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "98724960-128d-4ecc-cdb0-460f7c06536e"
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKYxE2MEB6LV"
      },
      "source": [
        "# Zip and Download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "865-t79uaB63"
      },
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC-MzW8ZXTa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "402d4e6c-da44-4815-fe0a-34a90e886e0d"
      },
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\r\n",
            "  adding: model/group5-shard1of1 (deflated 7%)\r\n",
            "  adding: model/model.json (deflated 82%)\r\n",
            "  adding: model/group2-shard1of1 (deflated 7%)\r\n",
            "  adding: model/group3-shard1of1 (deflated 7%)\r\n",
            "  adding: model/class_names.txt (deflated 41%)\r\n",
            "  adding: model/group1-shard1of1 (stored 0%)\n",
            "  adding: model/group4-shard1of1 (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vfPR03xZZeD"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}